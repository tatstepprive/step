#source for prometheus downloads
https://prometheus.io/download/
#==============================
#Install on redhat steps
useradd -m -s /sbin/nologin prometheus
mkdir /etc/prometheus
mkdir /var/lib/prometheus
wget https://github.com/prometheus/prometheus/releases/download/v2.14.0/prometheus-2.14.0.linux-amd64.tar.gz -P /tmp
cd /tmp
tar -zxpvf prometheus-2.14.0.linux-amd64.tar.gz
cd /tmp/prometheus-2.14.0.linux-amd64
cp prometheus promtool /usr/local/bin/
cp -r consoles/ console_libraries/ /etc/prometheus/
sudo chown -R prometheus:prometheus /var/lib/prometheus/
sudo chown -R prometheus:prometheus /etc/prometheus/
vi /etc/prometheus/prometheus.yml
------------------------------------------------
# Global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. 
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. 
  scrape_timeout: 15s  # scrape_timeout is set to the global default (10s).
# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'
    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.
    static_configs:
#    - targets: ['localhost:9090']
    - targets: ['localhost:3004']
--------------------------------------------------------
vi /etc/systemd/system/prometheus.service
[Unit]
Description=Prometheus
Documentation=https://prometheus.io/docs/introduction/overview/
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
User=prometheus
Group=prometheus
Type=simple
ExecStart=/usr/local/bin/prometheus \
    --config.file /etc/prometheus/prometheus.yml \
    --storage.tsdb.path /var/lib/prometheus/ \
    --web.console.templates=/etc/prometheus/consoles \
    --web.console.libraries=/etc/prometheus/console_libraries \
    --web.listen-address=0.0.0.0:3004

[Install]
WantedBy=multi-user.target
-------------------------------------------
sudo systemctl daemon-reload
sudo systemctl start prometheus
#=================================================================
Prometheus alternatives:
graphite
opentsdb
sensu
influxdb
nagios
#==================================================================
Target=definition of object to scrape, object whose metrics are to be monitored
Instance=endpoint host:port1, host:port2, host2:port1, host2:port2
Job=collection of targets/instances with same purpose
Sample=single value at a point in time in a time series
Exporter=software or number of libraries and servers that help to export existing metrics from 3d-party systems (like Linux or Windows OS) in the same format as of prometheus metrics, useful when original prometheus metrics are not sufficient like gathering Linux system stats (prometheus-exporter(f: gather data and transfor to correct format readable for prometheus)-linux system) 
Exporter exp: 
* Node Exporter f: hardware and OS metrics exposed by *NIX kernels (metrics as cpu, memory, disk usage, disk I/O, network bandwidth)
* WMI Exporter f: hardware and OS matrics exporsed by Windows OS (WMI=windows management instrumentation)
PromQL=prometheus query language
#==================================================================
PromQL data types:
* Instant vector (prometheus_http_requests_total: 1 value for each setting))
* Range vector (prometheus_http_requests_total[1m]: multiple values for each setting))
* Scalar (simple numeric floating point value)
* String (charakter value, not used according to documentation)
#===================================================================
Matchers and Selectors.
Matcher:
* Equality matcher =
* Negative Equality matcher !=
* Regular Expression matcher =~
* Negative Regular Expression matcher !~
Operatiors:
* Binary operators (f: takes 2 operands)
  ** Arithmetic (+,-,*,/,%,^)
  ** Comparison (==, !=, >, <, >=, <=)
  ** Logical/set ( and, or, unless)
* Aggregation operators (sum(), min(), max(), avg(), stddev(), stdvar(), count(), count_values(), bottomk(), topk(), quantile())

Selector: process_cpu_seconds_total{job="prometheus"}
#====================================================================
Infrastructure: Prometheus server: retrieval, tsdb/storage, http_server 
Prometheus server pull metrics from targets (jobs/exporters)
Pushgateway: short lived jobs push metrics at exit to pushgateway, prometheus server pull metrics from pushgateway
Service discovery: f: discover targets (2 ways to find targets: hardcode or service discovery)
Data visualization and exports: prometheus web ui, grafana, api clients
Prometheus alerting:prometheus server push alerts to alert manager and he notifies via email, paperduty, slack, etc

#=====================================================================
Metrics:
up (f: scraping data about prometheus self on localhost up{instance="localhost:9090", job="prometheus"} 1); value 1 means the script was successful
#=========================================================================
