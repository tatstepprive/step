#Constraints
#Constraint types
NOT NULL (column can not be null) (type C) (name_nn) (can not be null) (many/table)
UNIQUE (must be unique, but can me many null values) (type U) (name_uk or name_uq) (can be null) (many/table)
PRIMARY KEY (=unique/not_null; identifies uniquely each row in the table, can be 1 or combination of column) (type P) (name_pk) (can not be null) (one/table)
FOREIGN KEY (references to pk in other table. Table with fk=child table; referenced table (other table)=parent table) (type R) (name_fk) (can be null) (many/table)
CHECK (condition) (type C) (name_chq) (can be null) (many/table)
Tip: see for types in user_constraints table
Tip: for fk constraint see R_CONSTRAINT_NAME to know column in other table
Tip: constraint name should be unique, so use <table>_pk, <table>_<column>_uk, <table>_<column>_fk, <table>_<column>_chq
Tip: (many/table) or (one/table) is how many constraint per table. Only pk is one per table.
Tip: only not null and pk constraint are never null
Tip: fk can be null, unique can be null and have many nulls
Tip: unique column can have many null values, nulls are not considered equal to anything, no uniqueness for nulls
Tip: indexes are only pk and fk
Tip: long column can not be used for constraint as pk, unique, fk (only not null constraint can be set)
Tip: unique key versus primary key: unique key allows null values, primary key does NOT allow null values
#Constraint guidelines
* Give name or oracle server gives SYS_Cn name format (can be renamed after)
* Create at table creation time or after
* On column or table level
#Constraint on delete for fk
constraint <constraint_name> foreign key (<this.column>) references <other_table> (<other_table_pk>) on delete cascade
f: if on other table delete row the rows with fk in this table will be removed too
constraint <constraint_name> foreign key (<this.column>) references <other_table> (<other_table_pk>) on delete set null
f: if on other table delete row the rows with fk in this table will be set on fk column to value null, so ref is removed but the row stays in this table
Tip: if no 'on delete' clause then row removal on other table will give error if the refs (fk) to row (pk) in remove operation exits
Tip: other table=main table with pk, this table=dependent table with fk to pk
Tip: you can temporary disable constraints without deleting it
Tip: when you disable pk or unique constraints, the releated index will be dropped, when enable again index will be recreated automatically
#Deferrable constraints
Deferrable constraint allow change constraint value in main table which is referred by fk in other table without many action like it was before (add new recored in main table with new value, change value in fk, remove old record in main table)
Everything is done in on step and applied on commit. Before oracle reacted before commit with error if you try to do operation explained above.
deferrable initially deferred f: constraint check will be postponed after commit, if error transaction will be rollbacked
deferrable initially immediate f: acting like normal behaviour, constraint will be checked/fired before commit, for ex by doing insert, if error direct error message shown
Tip: when creating constraint with option deferrable initially (default is not deferred), you can change behaviour by set constraint <constraint_name> immediate (only for current session);
#========================================================
#Table
Alter table when:
add new column (alter table <table_name> add <column_name_and_definition> [ not null default 'my_value']) 
modify column definition exp: size, type, default (alter table <table_name> modify <column_name_and_definition>)
rename column (alter table <table_name> rename column <old_name> to <new_name>;)
set column unused (alter table <table_name> set unused [column] <column_name>)
drop column (alter table <table_name> drop <column_name>)
add new constraint
rename constraint
disable constraint
drop constraint
change table status read-only, read-write (alter table <table_name> read only;) (alter table <table_name> read write;) f: DML are not allowed, DDL are stil allowed like add column, drop table
Tip: the added column will be always the last column, can not specify place
Tip: select * from user_unused_col_tabs;

Rename table: (never do on production)
rename <old_table_name> to <new_table_name>;

Drop table:
drop table <table_name> [purge];
Tip: drop table moves it in recyclebin (select * from user_recyclebin where original_name=<dropped_table_name>)
Tip: drop table with purge option removes it permanently (select * from user_recyclebin where original_name=<dropped_table_name> --output no rows )
#GTT=global temporary table f: rows exist only for the duration of the transaction (session), each session can see and modify only its data
# benefit: fast, all rows manipulations are in memory, no redo logs
create global temporary table my_glob
(item_nr number, 
item_desc varchar2(100)) 
on commit delete rows; -- on commit rows deleted
--on commit preserve rows; -- on commit rows stay in the table, when session ends then rows are removed

--show all temporary tables:
select table_name
from all_tables
where TEMPORARY = 'Y';

#External tables and sqlloader
sqlloader f: move data from external files (xxx.csv) into oracle database
xxx.csv file contains data separated by comma, space etc
create control file xxx.ctl with content:
---------------
Load Data
INFILE 'C:\data\emp.csv'
APPEND
INTO TABLE my_emp
FILEDS TERMINATED BY ','
(emp_id,
fname,
lname
)
--------------
execute on command line:
sqlldr control=C:\data\emp.ctl log=C:\data\emp.log
password: user/pass@db
result: emp log created, if bad rows emp.bad log file created, the data is inserted in the table defined in control file
#External table = read-only table with metadata stored in database, but data stored outside the database, no dml allowed, no indexes, constrains, triggers can be created on it, it's file on os)
Data in external table come from xxx.csv file or from xxx.dump file on disk, no data are really loaded, just viewed and can not be manipulated.
Syntax:
create table my_table
(emp_id number,
fname varchar2(100),
lname varchar2(100)
)
organization external 
(type oracle_loader
default directory my_dir
access parameters 
  (records delimited by newline
  fields terminated by ','
  )
location ('my_data.csv')
)
reject limit unlimited;

#Table with partitions
Partitioning=dividing table into multiple pieces, improves performance on big table. Data management operations on partition level.
* range partitioning
* interval partitioning (auto creation of partition)
* list partitioning
* hash partitioning
* composite partitioning

--range partitioning
create table sales_od (
customer_id number,
order_date date,
order_amount number,
region varchar2(10)
)
partition by range (order_date)
(
partition sales_p2101 values less than (to_date('2021-01-01', 'YYYY-MM-DD')),
partition sales_p2102 values less than (to_date('2021-02-01', 'YYYY-MM-DD')),
partition sales_p2103 values less than (to_date('2021-03-01', 'YYYY-MM-DD')),
partition sales_p2104 values less than (to_date('2021-04-01', 'YYYY-MM-DD')),
...
partition sales_pmax values less than (MAXVALUE))
);

insert into sales_od values(1,'25-jan-21',10,'west');
select * from sales_od;
select * from sales_od partition(sales_p2102);

--interval partitioning to avoid ORA-14400 inserted partition key does not map to any partition
create table sales_odi (
customer_id number,
order_date date,
order_amount number,
region varchar2(10)
)
partition by range (order_date)
interval ( NUMTOYMINTERVAL(1, 'MONTH'))
(
partition sales_p2107 values less than (to_date('2021-07-01', 'YYYY-MM-DD')),
partition sales_p2108 values less than (to_date('2021-08-01', 'YYYY-MM-DD')),
partition sales_p2109 values less than (to_date('2021-09-01', 'YYYY-MM-DD')),
partition sales_p2110 values less than (to_date('2021-10-01', 'YYYY-MM-DD')),
partition sales_pmax values less than (MAXVALUE))
);

insert into sales_odi values(1,'25-jan-21',10,'west');
select * from sales_odi;
select * from sales_odi partition(sales_p2102);


--list partitioning
create table sales_r (
customer_id number,
order_date date,
order_amount number,
region varchar2(10)
)
partition by list (region)
(
partition rw values ('west'),
partition re values ('east'),
partition rns values ('north', 'south')
);

insert into sales_r values(1,'25-jan-21',10,'west');
select * from sales_r;
select * from sales_r partition(rw);

--hash partitioning
create table sales_h (
customer_id number,
order_date date,
order_amount number,
region varchar2(10)
)
partition by hash (customer_id)
(
partition d1,
partition d2,
partition d3
);

insert into sales_r values(1,'25-jan-21',10,'west');
select * from sales_d;
select * from sales_r partition(d1);
select * from sales_r partition(d2);
select * from sales_r partition(d3);

--composite partitioning (like multi-array)
create table sales_c ( 
customer_id number,
order_date date,
order_amount number,
region varchar2(10)
)
partition by range (order_date)
subpartition by hash (customer_id) subpartitions 4
(
partition sales_p2101 values less than (to_date('2021-01-01', 'YYYY-MM-DD')),
partition sales_p2102 values less than (to_date('2021-02-01', 'YYYY-MM-DD')),
partition sales_p2103 values less than (to_date('2021-03-01', 'YYYY-MM-DD')),
partition sales_p2104 values less than (to_date('2021-04-01', 'YYYY-MM-DD')),
partition sales_pmax values less than (MAXVALUE))
);

insert into sales_c values(1,'25-jan-21',10,'west');
select * from sales_c;
select * from sales_c partition(sales_p2101);

--show partitions
select * from all_tab_partiotions where table_name like 'SALE%';

--add partition
ALTER TABLE SALES_OD ADD PARTITION
(PARTITION 'P2001' VALUES LESS THAN TO_DATE ('2020-01-01', 'YYYY-MM-DD'));

--drop partition
ALTER TABLE SALES_OD DROP PARTITION P2001;
#======================================================
#View=named select statement
simple view=select on 1 table, not contain functions, no groups data, dml operations throgh the view
complex view=select on one/many tables, contain functions (max(), min()), groups data (distinct, group by), not always dml operation through the view
create [or replace] [force|noforce] view <view_name> as subquery [with read only];
noforce= is default, create view only if base tables exist
with read only=no dml operation are allowed
select * from user_views;
#View vs materialized view
* view is never stored only displyed; materialized view is stored on the disk
* view is virtual table formed from one/many basic tables or views; materialized view is a physical copy of the base table
* view is updated each time when virtual table (view) is used; materialized view has to be updated manually or using triggers
* speed for view is slow processing; speed for materialized view is fast processing
* memory: view do not require memory space; materialized view use memory space
* syntax: create view <view_name> as ...; create materialized view <view_name> build [clause] refresh [clause] on [trigger] as ...;   
#======================================================
#Sequence
create sequence <seq_name> (seq_name=xxx_seq)
increment by <int> --(default 1)
start with <int>   --(default 1)
maxvalue <int>| nomaxvalue --(default nomaxvalue)
minvalue <int>| nominvalue --(default nominvalue)
cycle | nocycle --f: generate value after reaching max, default nocycle
cache <int> | nocache --f: preallocate and keep in memory, default 20 values
order | noorder; --(default noorder)

Sequence is separete from table object and can be shared (used for multiple tables)
Used for create pk values
select * from user_sequences;
insert into test1 (id, fname) values (<seq_name>.nextval, 'diana');
--show current value
select <seq_name>.currval from dual;
--get next value, executing without exection will create a gap
--gap will be created too when rollback issued
select <seq_name>.nextval from dual;
Tip: the start with option cannot be changed using alter sequence. 
the sequence must be dropped and re-created to restart the sequence with a different number
#=======================================================
#Synonyms (=alternative name for object, no storage only entry in data dictionary)
private
public
create [public] synonym for object;
exp: create synonym e for employees; select * from e; drop synonym e;
exp: create public synonym em for hr.employees;
select * from user_synonyms;
select * from all_synonyms;
Tip: invalid synonyms trick. Using synonym can give error when the status column is 'VALID', it happens when referenced valid object is dropped, as result the synonym is pointing to dead end, to nothing.
You can query the ALL_OBJECTS view for object_type = 'SYNONYM' and status != 'VALID'. 
However all_objects status is set based on the status of the object that it is referring to. Synonyms, which aren't automatically invalidated if the underlying table disappears. So the STATUS column of ALL_OBJECTS is not reliable to use.
For monitoring you need to find dead end (deleted,dropped referenced object) to avoid exception like
 "ORA-01775: looping chain of synonyms" => (because public synonym still exists but referencing table have been dropped)
#=======================================================
#Index (f: pointer to speed up query, dropped with dropping table, can be dropped independent)
automatically (when pk or unique constraints are created, name=pk or name=sys_cxxx when unique constraint)
manually
create [unique][bitmap] index <index_name> on table (column...); --index_name=xxx_idx
select * from user_indexes; --to find index on table
select * from user_ind_columns; -- to find column name with index
select * from user_ind_expressions; -- to find index column name for index sys_ncxxx
#Index creation guidelines
* column contains a wide range of values
* column contains a large number of null values
* column is frequenty used in where or join condition
* table is large
* table is updated not frequently
alter index a rename to b; 
Question: can i rename index SYS_ILxxx? (it's lob index)
#=======================================================
#Dictionary views prefix
user_xxx f: user's view, what is in your schema, what you own
all_xxx  f: expanded user's view (what you can access so your objects and granted objects, has owner column)
dba_xxx  f: db admin's view (what is in everyone's schema, has owner column)
v$xxx    f: dynamic db views, performance releated data
select * from dictionary where table_name='USER_OBJECTS'; --you can use short name: select * from dict where table_name='USER_OBJECTS'
select * from dict where table_name like 'V$%'; -- show all dynamic views 
select * from dictionary; --about 1000 rows (961 rows)
select * from user_catalog; --contains table, view, index, synonym, sequence of user
select * from cat; -- same as from user_catalog
select * from user_objects;
select * from all_objects;
select * from dba_objects; --only for sys or system default
select * from user_tables;
select * from tabs; --same as from user_tables;
select * from user_tab_columns;
select * from all_tables; 
select * from all_tab_columns;
select * from user_constraints;
select * from user_cons_columns;
select * from all_constraints;
select * from all_cons_columns;
select * from user_tab_comments;
select * from user_col_comments;
#=======================================================
#optimiser hint: parallel query
select /*+ PARALLEL(emp,4) */ * FROM emp
#======================================================
